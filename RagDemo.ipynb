{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":25092,"status":"ok","timestamp":1706242390622,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"63EtYTvnu1r4"},"outputs":[],"source":["%%capture\n","!pip install  tiktoken faiss-cpu\n","!pip install -U sentence-transformers\n","!pip install langchain\n","!pip install pypdf\n","!pip install langchain-huggingface"]},{"cell_type":"markdown","metadata":{},"source":["tiktoken -tiktoken is a fast BPE tokeniser. Byte pair encoding (BPE) is a way of converting text into tokens. \n","faiss-cpu -A library for efficient similarity search and clustering of dense vectors.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4085,"status":"ok","timestamp":1706242394703,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"sjmRd93XvAmj","outputId":"e4e8e34f-508d-44e5-f755-f391688909c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["OrderedDict([('GROQ_API_KEY', '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'), ('HUGGINGFACEHUB_API_TOKEN', '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'), ('OPENAI_API_KEY', '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')])\n"]}],"source":["import os\n","from dotenv import dotenv_values\n","config = dotenv_values(\".env\")\n","print(config)\n","os.environ[\"GROQ_API_KEY\"] = config[\"GROQ_API_KEY\"]\n"]},{"cell_type":"markdown","metadata":{"id":"NuzRSeWYwOn5"},"source":["# üîç **Retrieval in LangChain Explained**\n","\n","<img src=\"https://python.langchain.com/assets/images/data_connection-95ff2033a8faa5f3ba41376c0f6dd32a.jpg\">\n","\n","### üåê **Basic Concept**\n","\n","Retrieval is like gathering resources to enhance an essay, helping language models access up-to-date, relevant information beyond their built-in knowledge.\n","\n","üí° **Advantages**:\n","   - Adds new, fresh information.\n","   - Makes responses more relevant and informed.\n","\n","üìö **Document Loaders**:\n","   - Function as \"specialized librarians.\"\n","   - Organize content from various sources for language models.\n","\n","üìÑ **Text Loader Fundamentals**:\n","   - Simple process: Converts text files into a usable format for language models.\n","\n","üéØ **Presentation Style**:\n","   - Brief and informative, ideal for a concise summary."]},{"cell_type":"markdown","metadata":{"id":"onMQEXT7wjMc"},"source":["# üîÑ **Document Loaders in LangChain**:\n","\n","üìã **Wide Selection**: Numerous document loaders available. Check the [documentation](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/document_loaders) for a full list.\n","\n","üë£ **Usage Steps**:\n","   1. Choose a Document Loader from LangChain.\n","   2. Create an instance of the Document Loader.\n","   3. Employ its `load()` method to convert files into LangChain documents.\n","\n","### üõ†Ô∏è **Role of Document Transformers**\n","\n","üìê **Customization for Models**: Adjust documents to suit your model's requirements, like trimming lengthy texts.\n","\n","### ‚úÇÔ∏è **Understanding Text Splitters**\n","\n","üî¢ **Function**: Divide long texts into smaller, coherent segments.\n","\n","üîó **Goal**: Keep related text together, fitting within the model's capacity.\n","\n","### üß© **Using `RecursiveCharacterTextSplitter`**\n","\n","üîÑ **Methodology**:\n","   - Intelligently splits texts using multiple separators.\n","\n","   - Recursively adjusts if segments are too large.\n","\n","   - Ensures all parts are appropriately sized.\n","\n","### üåü **Key Aspects of Splitting**\n","\n","   - Chooses optimal separators for division.\n","\n","   - Continually splits large chunks.\n","\n","   - Balances chunk size by characters or tokens.\n","\n","   - Maintains some overlap for context.\n","\n","   - Tracks chunk starting points if needed.\n","\n","üéØ **Presentation Style**\n","\n","   - Focused on essential steps and features, great for a concise summary."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":138,"status":"ok","timestamp":1706243341736,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"4gItthdswrME"},"outputs":[],"source":["from langchain_community.document_loaders import PyPDFDirectoryLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","loader=PyPDFDirectoryLoader(\"./ncs_docs\")\n","docs=loader.load() ## Document Loading\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["1003"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(docs)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'>\n","328\n"]}],"source":["splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap = 200)\n","final_documents=splitter.split_documents(docs[:100]) #splitting\n","print(type(final_documents))\n","print(len(final_documents))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"OsF1E9sUyhL-"},"source":["# üåê **Text Embeddings Overview**\n","\n","üî¢ **Functionality**: Converts documents into numerical vectors in LangChain.\n","\n","ü§ù **Similarity Measure**: Vectors that are closer indicate more similar texts.\n","\n","üîç **Application**: Quickly identify documents with similar topics or content.\n","\n","üéØ **Presentation Style**: Concise and clear, ideal for slides or quick explanations."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/nokia/LangChainPromptCourse/venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n","/home/nokia/LangChainPromptCourse/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["#from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain.embeddings import HuggingFaceEmbeddings\n","\n","# Define the path to the pre-trained model you want to use\n","modelPath = \"sentence-transformers/all-mpnet-base-v2\"\n","#modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n","\n","# Create a dictionary with model configuration options, specifying to use the CPU for computations\n","model_kwargs = {'device':'cpu'}\n","\n","# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n","encode_kwargs = {'normalize_embeddings': False}\n","\n","# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n","HuggingFaceembeddings = HuggingFaceEmbeddings(\n","    model_name=modelPath,     # Provide the pre-trained model's path\n","    model_kwargs=model_kwargs, # Pass the model configuration options\n","    encode_kwargs=encode_kwargs # Pass the encoding options\n",")"]},{"cell_type":"markdown","metadata":{"id":"Wn6N5TfLq1Js"},"source":["# üõ†Ô∏è **Creating a Vector Store Retriever**\n","\n","1. **Load Documents**: Utilize a document loader for initial document retrieval.\n","\n","2. **Split Texts**: Break down documents into smaller sections with a text splitter.\n","\n","3. **Embedding Conversion**: Apply an embedding model to transform text chunks into vectors.\n","\n","4. **Vector Store Creation**: Compile these vectors into a vector store.\n","\n","üîç **Outcome**: Your vector store is now set up to search and retrieve texts by content."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3941,"status":"ok","timestamp":1706243462944,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"tMTITqujy-Ny"},"outputs":[],"source":["from langchain.vectorstores import FAISS\n","\n","vectorstore = FAISS.from_documents(documents=final_documents, embedding=HuggingFaceembeddings)"]},{"cell_type":"markdown","metadata":{"id":"Ukx_BoFuqWgh"},"source":["# üîé **Vector Store as a Retriever**\n","\n","1. **Search Engine Role**: The vector store functions like a document search engine.\n","\n","2. **Similarity Searches**: Find documents similar to your provided text.\n","\n","3. **Customization Options**: Specify match selectivity and desired number of top results.\n","\n","‚ú® **Functionality**: Use `similarity_search` to pinpoint documents closely matching your specified text, with flexibility in refining search parameters."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":473,"status":"ok","timestamp":1706243566964,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"JoBei3GpskW8","outputId":"c7e40b7a-2b25-45ec-edc5-10d1d628c6fb"},"outputs":[{"data":{"text/plain":["[Document(metadata={'source': 'ncs_docs/NCS20FP2-Operations_and_Administration_Manual.pdf', 'page': 30}, page_content='Operations and Administration Manual NCS command line (CLI)\\n4NCS command line (CLI)\\nNCS provides a command line interface (CLI) for use in updating cluster configuration information. There\\nare multiple ways to access the CLI:\\n‚Ä¢Via a Control node.\\n‚Ä¢Via the Deployment Server.\\nNokia Container Services\\nRelease 20 FP2DN1000040981 1-6\\n¬©2022 Nokia. Nokia Confidential Information\\nUse subject to agreed restrictions\\non disclosure and use.31Copyrighted material licensed to shimon.tanny@nokia.com on 26-01-2023. No further reproduction or networking is permitted. Distributed by Nokia.'),\n"," Document(metadata={'source': 'ncs_docs/NCS20FP2-Operations_and_Administration_Manual.pdf', 'page': 61}, page_content='Operations and Administration Manual Cluster management\\n4.Log in to the NCS admin container using the following command:\\ndocker exec -it bcmt-admin bash\\n5.Set the endpoint to point to one of the Control nodes using the ncs config  command:.\\nncs config set --endpoint=https://<control node IP>:<port>/ncm/api/v1\\nExample command:\\nncs config set --endpoint=https://10.0.2.1:8082/ncm/api/v1\\nNote :  For Baremetal deployment, use port 8084 instead of 8082.\\n6.Log in in using the ncs user login  command.\\nncs user login --username=<username> --password=<password>\\nExample command:\\nncs user login --username=ncs-admin --password=NewPassword@1234!\\n7.Add the node‚Äôs information to the cluster inventory using the ncs node add  command. (Skip this step\\nif embedded_clcm is true.)\\nCommand syntax:\\nNAME:\\n   ncs node add - add node to cluster\\nUSAGE:\\n   ncs node add [command options] [arguments...]\\nOPTIONS:\\n   --inventory    <node inventory file>    specifies the node inventory\\n file to be loaded'),\n"," Document(metadata={'source': 'ncs_docs/NCS20FP2-Operations_and_Administration_Manual.pdf', 'page': 38}, page_content='NAME:\\n   ncs user add - add a new user\\nUSAGE:\\n   ncs user add [command options] [arguments...]\\nOPTIONS:\\n   --username     <user name>    specifies the user name\\n   --email        <email>        specifies the user email of the user(optional)\\n   --firstname    <user name>    specifies first name of the user(optional)\\n   --lastname     <user name>    specifies last name of the user(optional)\\nNokia Container Services\\nRelease 20 FP2DN1000040981 1-6\\n¬©2022 Nokia. Nokia Confidential Information\\nUse subject to agreed restrictions\\non disclosure and use.39Copyrighted material licensed to shimon.tanny@nokia.com on 26-01-2023. No further reproduction or networking is permitted. Distributed by Nokia.'),\n"," Document(metadata={'source': 'ncs_docs/NCS20FP2-Operations_and_Administration_Manual.pdf', 'page': 57}, page_content='Operations and Administration Manual Cluster management\\n3.Log in to the NCS admin container using the following command:\\ndocker exec -it bcmt-admin bash\\n4.Set the endpoint to point to one of the Control nodes using the ncs config  command:\\nncs config set --endpoint=https://<control node IP>:<port>/ncm/api/v1\\nExample command:\\nncs config set --endpoint=https://10.0.2.1:8082/ncm/api/v1\\nNote :  For Baremetal deployment, use port 8084 instead of 8082.\\n5.Optional: Log in using the ncs user login  command:.\\nncs user login --username=<username> --password=<password>\\nExample command:\\nncs user login --username=ncs-admin --password=NewPassword@1234!\\n6.Remove a node from the cluster using the ncs cluster scale-in  command. Multiple nodes can be\\nspecified by separating each node name with a comma.\\nNAME:\\n   ncs cluster scale-in - scale-in ncs VMs\\nUSAGE:\\n   ncs cluster scale-in [command options] [arguments...]\\nOPTIONS:\\n   --node_names    <node names>    specifies the name of nodes need to be')]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["query = \"NCS command line\"\n","\n","vectorstore.similarity_search(query)"]},{"cell_type":"markdown","metadata":{"id":"P5quhR5asvju"},"source":["# Generate"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":9737,"status":"ok","timestamp":1706243770715,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"BwZKC0Yzs3ta","outputId":"e370cd9f-dbee-4e61-f9da-ec9b095ad92c"},"outputs":[{"data":{"text/plain":["'Here\\'s an example of using the NCS command line to add a new user:\\n\\n`ncs user add --username=john --email=john@example.com --firstname=John --lastname=Doe`\\n\\nThis command adds a new user with the username \"john\", email \"john@example.com\", first name \"John\", and last name \"Doe\".'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.chains import RetrievalQA\n","\n","from langchain.prompts import PromptTemplate\n","\n","from langchain_groq import ChatGroq\n","\n","template = \"\"\"\n","\n","Use the following pieces of context to answer the question at the end.\n","\n","If you don't know the answer, just say 'Ah snap homie, I ain't gonna front. I don't know.`, don't try to make up an answer.\n","\n","Use three sentences maximum, relevant analogies, and keep the answer as concise as possible.\n","\n","Use the active voice, and speak directly to the reader using concise language.\n","{context}\n","\n","Question: {question}\n","\n","Helpful Answer:\n","\n","\"\"\"\n","\n","QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n","\n","llm = ChatGroq(model=\"llama3-8b-8192\",temperature=0.7)\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectorstore.as_retriever(),\n","    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",")\n","\n","\n","query = \"can you give an example for NCS command line\"\n","\n","\n","result = qa_chain.invoke({\"query\": query})\n","\n","result[\"result\"]"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
